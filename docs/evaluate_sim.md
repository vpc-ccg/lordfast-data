# Evaluation of mappings for simulated reads

In order to evaluate the mappings generated by a tool, we first need to convert the alignments to [m5 format](https://github.com/PacificBiosciences/blasr/wiki/Blasr-Output-Format):
```
codes/sam2m5/sam2m5 reference.fa mapping.sam 1 > mapping.m5
```
The above command only converts primary and supplementary alignments. In case you need to convert secondary alignments as well, pass mode `2` as the option.

We can then run the evaluation tool as follows:
```
codes/sim_evaluate/evaluate reads.fasta true.m5 mapping.m5 corDistLimit minOverlap
```
where `reads.fasta` and `true.m5` respectively contain reads generated by PBSIM and ground truth mappings generated by PBSIM as explained [here](https://github.com/vpc-ccg/lordfast-extra/blob/master/docs/sim_human.md), `mapping.m5` are mappings reported by the tool of interest. A **base** is considered to be "correctly mapped" if its mapped location is within `corDistLimit` of the true alignment locus of the base. A **read** is considered to be "correctly mapped" if its alignment overlaps with at least `minOverlap` of the true alignment.

This will output `9` numbers separated by `&`. These numbers are:
1. total number of reads
2. number of mapped reads
3. number of correctly mapped reads
4. total number of bases
5. number of correctly mapped bases
6. number of incorrectly mapped bases
7. number of unmapped bases
8. sensitivity
9. precision

**NOTE:** One could evaluate mappings generated by multiple files using `run_all.py` as follows:
```
python codes/sim_evaluate/run_all.py -r reads.fa -t true.m5 [-d baseDist -m minOverlap] label1,mapping1.m5 [label2,mapping2.m5 ...]
```
which will generate a Latex style table with each row corresponding to one mapping file.
